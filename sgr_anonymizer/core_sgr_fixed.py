# sgr_anonymizer/core_sgr_fixed.py
import json
from .utils import clean_json_string, anonymize_with_tags, regex_safety_net, compress_repeated_tags
from . import schemas
from .schemas.contextual_phone_words import ContextualPhoneWordsExtraction
from .schemas.contextual_email_words import ContextualEmailWordsExtraction

# Используем ваш LLMClient
from llm_client import LLMClient

class SGRFixedAnonymizer:
    """
    Исправленная SGR система с правильными промптами для каждой схемы
    Соответствует ФЗ-152 и SGR методологии
    """
    def __init__(self):
        self.llm = LLMClient()
        
        # Правильный порядок схем (сначала ФИО, потом остальное)
        # Важно: ФИО первым, чтобы другие схемы не захватывали имена
        # Используем контекстные схемы для телефонов и email словами согласно SGR методологии
        self.schemes = [
            (schemas.FIOExtraction, "ФИО"),
            (schemas.PhoneDigitsExtraction, "ТЕЛЕФОН"),
            (ContextualPhoneWordsExtraction, "ТЕЛЕФОН"),  # Контекстная схема для телефонов словами
            (schemas.EmailExtraction, "EMAIL"),
            (ContextualEmailWordsExtraction, "EMAIL"),  # Контекстная схема для email словами
            (schemas.AddressExtraction, "АДРЕС"),
            (schemas.PassportExtraction, "ПАСПОРТ"),
            (schemas.SnilsExtraction, "СНИЛС"),
            (schemas.InnExtraction, "ИНН"),
            (schemas.BankCardExtraction, "НОМЕР КАРТЫ"),
            (schemas.BirthDateExtraction, "ДАТА РОЖДЕНИЯ"),
            (schemas.FamilyExtraction, "РОДСТВЕННАЯ СВЯЗЬ"),
            (schemas.IpExtraction, "IP-АДРЕС"),
        ]

    def _safe_json_load(self, raw: str):
        """
        Пытается аккуратно распарсить JSON: очистка, вырезание по первому '{' и последней '}'.
        """
        cleaned = clean_json_string(raw)
        try:
            return json.loads(cleaned)
        except Exception:
            start = cleaned.find('{')
            end = cleaned.rfind('}')
            if start != -1 and end != -1 and end > start:
                candidate = cleaned[start:end+1]
                return json.loads(candidate)
            raise

    def _generate_extraction(self, text: str, schema_cls):
        """
        Генерация с повторными попытками при ошибках парсинга JSON.
        """
        last_err = None
        base_prompt = self._build_sgr_prompt(text, schema_cls)
        reinforce_suffix = "\n\nОГРАНИЧЕНИЕ: Верни ТОЛЬКО валидный JSON строго по SCHEMA, без комментариев и текста."

        for attempt in range(2):
            try:
                prompt = base_prompt if attempt == 0 else base_prompt + reinforce_suffix
                raw = self.llm.generate(prompt, temperature=0.0, max_tokens=1200)
                data = self._safe_json_load(raw)
                return schema_cls(**data)
            except Exception as e:
                last_err = e
                continue
        raise last_err

    def _build_sgr_prompt(self, text: str, schema_cls) -> str:
        """
        Строит SGR промпт для каждой схемы с четкими инструкциями
        """
        schema_json = schema_cls.model_json_schema()
        schema_description = schema_cls.__doc__.strip() if schema_cls.__doc__ else ""
        
        # ФИО - первая и самая важная схема
        if schema_cls.__name__ == "FIOExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие ФИО (фамилия, имя, отчество) по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки ВСЕ ФИО: полные, частичные, отдельные имена и фамилии
2. ВАЖНО: Если видишь "меня зовут X" или "зовут X" - X это ВСЕГДА ФИО (даже если это одно слово: "константин", "яна", "тимур")
3. НЕ извлекай телефоны, email, адреса, номера документов
4. Обоснуй в justification, почему найденные ФИО — ПДн
5. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ТОЛЬКО ФИО: имена, фамилии, отчества
- Примеры ФИО:
  * Полные: "Петров Иван Сергеевич", "Иван Сергеевич"
  * Частичные: "Петров", "Иван", "Сергеевич"
  * ОДИНОЧНЫЕ ИМЕНА после "меня зовут" или "зовут": "константин", "яна", "тимур", "мария", "алексей", "марина"
  * Инициалы и смешанные формы: "Иван И.", "И. И. Петров", "Иван И Петров"
  * Фамилии: "лескина", "петров", "иванов"
- МАРКЕРЫ ФИО: "меня зовут", "зовут", "это", "звать", "как к вам обращаться", "имя фамилия"
- НЕ ИЩИ телефоны: "8920583035", "плюс семь" - это НЕ ФИО
- НЕ ИЩИ email: "ivan@mail.ru", "мария@mail.ru" - это НЕ ФИО (email содержит символ @ или слова "собака", "точка")
- НЕ ИЩИ адреса: "Москва, улица Тверская" - это НЕ ФИО
- НЕ ИЩИ теги типа "[ФИО]", "[ТЕЛЕФОН]", "[EMAIL]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках

SGR МЕТОДОЛОГИЯ:
- Анализируй контекст диалога для определения ФИО
- Учитывай формы обращения: "меня зовут X" → X это ФИО (даже одно слово!)
- "Это X" → X это ФИО
- "X звоню" → X это ФИО
- Ищи все повторяющиеся упоминания одного ФИО
- ОДИНОЧНОЕ ИМЯ после маркера ФИО - это тоже ФИО!

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Телефоны цифрами
        elif schema_cls.__name__ == "PhoneDigitsExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие телефонных номеров (цифрами) по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки ВСЕ телефонные номера в цифровом формате
2. НЕ извлекай телефоны словами (для них есть другая схема)
3. НЕ извлекай ФИО, email, адреса
4. Обоснуй в justification, почему найденные номера — ПДн
5. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ТОЛЬКО ЦИФРОВЫЕ ТЕЛЕФОНЫ: "8920583035", "+79161234567", "8-916-123-45-67"
- НЕ ИЩИ телефоны словами: "плюс семь девятьсот" - это для другой схемы
- НЕ ИЩИ ФИО: "мария", "иван" - это НЕ телефоны
- НЕ ИЩИ email: "ivan@mail.ru" - это НЕ телефоны
- НЕ ИЩИ теги типа "[ТЕЛЕФОН]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках

SGR МЕТОДОЛОГИЯ:
- Телефонные номера содержат только цифры, пробелы, дефисы, скобки, знак +
- Обычно 10-11 цифр для российских номеров
- Форматы: +7XXXXXXXXXX, 8XXXXXXXXXX, (XXX) XXX-XX-XX

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Контекстные телефоны словами
        elif schema_cls.__name__ == "ContextualPhoneWordsExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие телефонных номеров (продиктованных словами) по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
ШАГ 1: Найди ВСЕ маркеры начала диктовки телефона в диалоге: "номер телефона", "телефон", "номер", "плюс", "диктуйте", "продиктую", "дайте телефон"
ШАГ 2: Для каждого найденного маркера:
   а) Найди реплику, содержащую маркер
   б) В этой же реплике найди числительные слова ПОСЛЕ маркера
   в) В следующих репликах (до нового маркера или изменения темы) найди ВСЕ числительные слова
ШАГ 3: Собери ВСЕ найденные части каждого телефона в fragments_to_replace
ШАГ 4: В fragments_to_replace укажи ТОЛЬКО числительные слова (без метаданных времени, без других слов)
ШАГ 5: НЕ извлекай телефоны цифрами (для них есть другая схема)
ШАГ 6: НЕ извлекай ФИО, email, адреса
ШАГ 7: Обоснуй в justification процесс восстановления номера

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ РЕАЛЬНЫЕ ДАННЫЕ, НЕ ТЕГИ! Например: "восемь девять два", "плюс семь девятьсот"
- НЕ ИЩИ теги типа "[ТЕЛЕФОН]" - это уже анонимизированные данные
- ИЩИ исходные телефонные номера словами в их естественном виде
- КОНТЕКСТНЫЕ МАРКЕРЫ: "продиктую телефон", "диктую номер", "номер телефона", "диктуйте", "продиктую"
- ФРАГМЕНТЫ ДИКТОВКИ: "восемь девять два", "плюс семь", "девятьсот семнадцать", "пятьсот одиннадцать"
- ФРАГМЕНТАРНАЯ ДИКТОВКА: Телефон может диктоваться по частям в разных репликах:
  * Пример: 
    Оператор: "диктуйте восемь девятьсот двадцать один"
    Клиент: "двадцать один"
    Оператор: "сот сорок четыре"
    Клиент: "шестьсот сорок четыре"
    → Это ОДИН телефон после маркера "диктуйте"
    → В fragments_to_replace укажи ВСЕ части: ["восемь девятьсот двадцать один", "двадцать один", "сот сорок четыре", "шестьсот сорок четыре"]
- НЕ ИЩИ телефоны цифрами: "8920583035" - это для другой схемы
- НЕ ИЩИ ФИО: "мария", "иван" - это НЕ телефоны
- НЕ ИЩИ email: "ivan@mail.ru" - это НЕ телефоны
- ИСКЛЮЧИ АДРЕСНЫЙ КОНТЕКСТ: если рядом слова "город", "улица", "дом", "квартира", "строение", "подъезд", "этаж" — это не телефон

SGR МЕТОДОЛОГИЯ:
- Анализируй ВЕСЬ диалог целиком, не только отдельные фразы
- Учитывай контекст: кто диктует, кто записывает
- Найди ВСЕ упоминания, включая повторы и уточнения
- Восстанови полный номер из разрозненных фрагментов
- Обрати внимание на диалоговые маркеры типа "Погодите", "А дальше?", "Повторите"

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Email
        elif schema_cls.__name__ == "EmailExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие email адресов по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки ВСЕ email адреса: обычные и продиктованные словами
2. НЕ извлекай ФИО, телефоны, адреса
3. Обоснуй в justification, почему найденные email — ПДн
4. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ТОЛЬКО EMAIL АДРЕСА:
  * Обычные: "ivan@mail.ru", "user@example.com" (содержат символ @)
  * Словами: "лесник собака майл точка ру", "ivan собака mail точка ru"
  * Маркеры email: слова "собака", "точка", "at", "@"
- НЕ ИЩИ ФИО: "мария", "иван", "петров" - это НЕ email (если нет символа @ или слов "собака", "точка")
- НЕ ИЩИ телефоны: "8920583035", "плюс семь" - это НЕ email
- НЕ ИЩИ адреса: "Москва, улица Тверская" - это НЕ email
- НЕ ИЩИ теги типа "[EMAIL]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках

SGR МЕТОДОЛОГИЯ:
- Email адрес ВСЕГДА содержит:
  * Символ @ (собака) ИЛИ слова "собака"/"at"
  * Доменное имя с "точка" или "."
  * Формат: username@domain.com или "username собака domain точка com"
- Если видишь только имя без @ или "собака" - это ФИО, НЕ email!

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Контекстные email словами
        elif schema_cls.__name__ == "ContextualEmailWordsExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие email адресов (продиктованных словами) по ФЗ-152 с учетом КОНТЕКСТА диалога.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Найди КОНТЕКСТНЫЕ МАРКЕРЫ: "продиктую почту", "диктую email", "электронная почта", "дайте почту"
2. Извлеки ВСЕ фрагменты диктовки (например: "митап", "четыре три два", "собака", "ин точка ру")
3. Восстанови полный email из фрагментов с учетом повторов и уточнений между оператором и клиентом
4. В поле fragments_to_replace укажи ВСЕ фрагменты: маркеры контекста + диктовка
5. Обоснуй в justification процесс восстановления email

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ РЕАЛЬНЫЕ ДАННЫЕ, НЕ ТЕГИ! Например: "митап четыре три два собака ин точка ру"
- НЕ ИЩИ теги типа "[EMAIL]" - это уже анонимизированные данные
- ИЩИ исходные email адреса словами в их естественном виде
- КОНТЕКСТНЫЕ МАРКЕРЫ: "продиктую почту", "диктую email", "электронная почта", "дайте почту"
- ФРАГМЕНТЫ ДИКТОВКИ: "митап", "четыре три два", "собака", "ин точка ру", "дот ком"
- ФРАГМЕНТАРНАЯ ДИКТОВКА: Email может диктоваться по частям:
  * Пример:
    Оператор: "продиктую почту: митап четыре три два"
    Клиент: "митап четыре три два"
    Оператор: "собака ин точка ру"
    → Это ОДИН email после маркера "продиктую почту"
    → В fragments_to_replace укажи ВСЕ части: ["митап четыре три два", "собака ин точка ру"]
- НЕ ИЩИ обычные email: "ivan@mail.ru" - это для другой схемы
- НЕ ИЩИ ФИО: "мария", "иван" - это НЕ email
- НЕ ИЩИ телефоны: "8920583035" - это НЕ email

SGR МЕТОДОЛОГИЯ:
- Анализируй ВЕСЬ диалог целиком, не только отдельные фразы
- Учитывай контекст: кто диктует, кто записывает
- Найди ВСЕ упоминания, включая повторы и уточнения
- Восстанови полный email из разрозненных фрагментов
- Обрати внимание на диалоговые маркеры типа "Погодите", "А дальше?", "Повторите"

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Адреса
        elif schema_cls.__name__ == "AddressExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие адресов по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки ВСЕ адреса: полные, частичные, словами
2. Включая адреса словами: "город екатеринбург", "улица хомякова дом двадцать", "дом тридцать девять квартира четыре"
3. НЕ извлекай ФИО, телефоны, email
4. Обоснуй в justification, почему найденные адреса — ПДн
5. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ВСЕ АДРЕСА:
  * Полные: "Москва, улица Тверская, дом 15, квартира 7"
  * Частичные: "город екатеринбург", "улица хомякова", "дом двадцать"
  * Словами: "город екатеринбург", "улица хомякова дом двадцать", "дом тридцать девять квартира четыре"
  * С указанием региона: "свердловская область город екатеринбург"
- МАРКЕРЫ АДРЕСОВ: "город", "улица", "дом", "квартира", "проезд", "проспект", "область", "край", "строение", "подъезд", "этаж"
- НЕ ИЩИ ФИО: "мария", "петров" - это НЕ адреса
- НЕ ИЩИ телефоны: "8920583035", "плюс семь" - это НЕ адреса
- НЕ ИЩИ email: "ivan@mail.ru" - это НЕ адреса
- НЕ ИЩИ теги типа "[АДРЕС]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках
- ОДИН ФРАГМЕНТ = ОДНО УПОМИНАНИЕ: fragments_to_replace ДОЛЖЕН содержать полную адресную фразу целиком (не разбивать на слова)
- ИСКЛЮЧИ ТЕЛЕФОННЫЙ КОНТЕКСТ: если рядом слова "телефон", "номер", "диктуйте", "плюс" — это не адрес

SGR МЕТОДОЛОГИЯ:
- Адреса содержат географические указатели: города, области, края, улицы, дома, квартиры
- Адреса могут быть продиктованы словами: "дом двадцать" вместо "дом 20"
- ВАЖНО: "город екатеринбург", "улица хомякова дом двадцать" - это адреса, даже если написаны словами!

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Паспорт
        elif schema_cls.__name__ == "PassportExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие паспортных данных по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки ВСЕ упоминания паспортных данных
2. Форматы: "серия 4512 номер 123456", "45 12 123456", "серия 4512 №123456"
3. НЕ извлекай ФИО, телефоны, email, адреса
4. Обоснуй в justification, почему найденные данные — ПДн
5. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ТОЛЬКО ПАСПОРТНЫЕ ДАННЫЕ: серия и номер паспорта
- Примеры: "серия 4512 номер 123456", "45 12 123456", "серия 5034 номер 567890"
- НЕ ИЩИ ФИО: "мария", "иван" - это НЕ паспорт
- НЕ ИЩИ телефоны, email, адреса
- НЕ ИЩИ теги типа "[ПАСПОРТ]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # ИНН
        elif schema_cls.__name__ == "InnExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие ИНН по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки ВСЕ упоминания ИНН
2. Форматы: "770123456789", "ИНН: 501234567890"
3. НЕ извлекай ФИО, телефоны, email, адреса
4. Обоснуй в justification, почему найденные ИНН — ПДн
5. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ТОЛЬКО ИНН: 10-12 цифр
- Примеры: "770123456789", "501234567890", "ИНН: 770123456789"
- НЕ ИЩИ ФИО: "мария", "иван" - это НЕ ИНН
- НЕ ИЩИ телефоны, email, адреса
- НЕ ИЩИ теги типа "[ИНН]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Номер карты
        elif schema_cls.__name__ == "BankCardExtraction":
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие номеров банковских карт по ФЗ-152.

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки ВСЕ упоминания номеров банковских карт
2. Форматы: "4276 1234 5678 9012", "5169123456789012"
3. НЕ извлекай ФИО, телефоны, email, адреса
4. Обоснуй в justification, почему найденные номера карт — ПДн
5. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ТОЛЬКО НОМЕРА КАРТ: 16 цифр (с пробелами или без)
- Примеры: "4276 1234 5678 9012", "5169123456789012", "карта 4276 1234 5678 9012"
- НЕ ИЩИ ФИО: "мария", "иван" - это НЕ номер карты
- НЕ ИЩИ телефоны, email, адреса
- НЕ ИЩИ теги типа "[НОМЕР КАРТЫ]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""
        
        # Остальные схемы (СНИЛС, дата рождения и т.д.)
        else:
            return f"""КОНТЕКСТ:
Проанализируй диалог на наличие персональных данных по ФЗ-152: {schema_description}

ДИАЛОГ:
{text}

ЗАДАЧА:
1. Извлеки все упоминания типа: {schema_description}
2. НЕ извлекай ФИО, телефоны, email, адреса (для них есть отдельные схемы)
3. Обоснуй в justification, почему они — ПДн
4. Укажи точные цитаты для замены в fragments_to_replace

КРИТИЧЕСКИ ВАЖНО:
- ИЩИ ТОЛЬКО данные типа: {schema_description}
- НЕ ИЩИ другие типы ПДн (для них есть отдельные схемы)
- НЕ ИЩИ теги типа "[...]" - это уже анонимизированные данные
- ИГНОРИРУЙ все теги в квадратных скобках

SCHEMA:
{json.dumps(schema_json, ensure_ascii=False, indent=2)}"""

    def _anonymize_single_pass(self, text: str) -> str:
        """
        Один проход анонимизации по всем схемам.
        """
        all_replacements = []  # [(fragment, tag), ...]

        for schema_cls, tag in self.schemes:
            try:
                extraction = self._generate_extraction(text, schema_cls)
                fragments = getattr(extraction, 'fragments_to_replace', [])
                for frag in fragments:
                    all_replacements.append((frag, tag))
            except Exception as e:
                print(f"Ошибка при обработке схемы {schema_cls.__name__}: {e}")
                continue

        return anonymize_with_tags(text, all_replacements)

    def anonymize(self, text: str, max_rounds: int = 3, use_regex_safety_net: bool = True) -> str:
        """
        Анонимизация с валидационным циклом: повторяем проходы, пока текст меняется,
        но не более max_rounds. В конце опционально применяем regex safety-net.
        """
        current = text
        for _ in range(max_rounds):
            updated = self._anonymize_single_pass(current)
            if updated == current:
                break
            current = updated

        if use_regex_safety_net:
            current = regex_safety_net(current)
            current = compress_repeated_tags(current)

        return current
